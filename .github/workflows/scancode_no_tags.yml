name: ScanCode Toolkit Scan

on:
  workflow_dispatch:
    inputs:
      scan_type:
        description: "Scan type"
        required: true
        type: choice
        options:
          - repo
          - zip
          - docker
        default: repo

      docker_image:
        description: "Docker image (if scan_type=docker)"
        required: false
        default: "alpine:latest"   # you can type anything when running workflow

      repo_url:
        description: "Repo URL (if scan_type=repo)"
        default: "https://github.com/psf/requests.git"

      archive_file:
        description: "Archive file (if scan_type=zip)"
        default: "sample.zip"

      enable_license_scan:
        type: boolean
        description: "Run license + license-text detection"
        default: true
      enable_copyright_scan:
        type: boolean
        description: "Run copyright + author + email detection"
        default: true
      enable_metadata_scan:
        type: boolean
        description: "Run metadata scans (urls + file info)"
        default: false
      enable_package:
        type: boolean
        description: "Detect packages and manifests"
        default: true
      enable_sbom_export:
        type: boolean
        description: "Export SPDX and CycloneDX SBOM"
        default: false

jobs:
  scancode:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout workflow repo
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt-get update && \
          sudo apt-get install -y git unzip jq python3 python3-pip && \
          pip3 install pandas openpyxl

      - name: Prepare input
        run: |
          set -euo pipefail
          SCAN_TYPE="${{ github.event.inputs.scan_type }}"
          REPO_URL="${{ github.event.inputs.repo_url }}"
          ARCHIVE_FILE="${{ github.event.inputs.archive_file }}"
          DOCKER_IMAGE="${{ github.event.inputs.docker_image }}"

          case "$SCAN_TYPE" in
            repo)
              git clone "$REPO_URL" input_repo
              INPUT_PATH="input_repo"
              LABEL="$(basename "${REPO_URL%.*}")"
              ;;
            zip)
              unzip -q "$ARCHIVE_FILE" -d input_zip
              INPUT_PATH="input_zip"
              base="$(basename "$ARCHIVE_FILE")"; LABEL="${base%.*}"
              ;;
            docker)
              docker pull "$DOCKER_IMAGE"
              docker save "$DOCKER_IMAGE" -o docker-image.tar
              INPUT_PATH="docker-image.tar"
              LABEL="$(echo "$DOCKER_IMAGE" | tr '/:' '__')"
              ;;
            *)
              echo "❌ Unknown scan_type: $SCAN_TYPE"
              exit 1
              ;;
          esac

          echo "INPUT_PATH=$INPUT_PATH" >> $GITHUB_ENV
          echo "SCAN_LABEL=$LABEL" >> $GITHUB_ENV

      - name: Download ScanCode Toolkit
        run: |
          git clone --depth 1 https://github.com/nexB/scancode-toolkit.git
          cd scancode-toolkit
          ./scancode --version

      - name: Run ScanCode Toolkit
        run: |
          cd scancode-toolkit
          SCANCODE_OPTS=""

          if [ "${{ github.event.inputs.enable_license_scan }}" = "true" ]; then
            SCANCODE_OPTS="$SCANCODE_OPTS --license --license-text"
          fi
          if [ "${{ github.event.inputs.enable_copyright_scan }}" = "true" ]; then
            SCANCODE_OPTS="$SCANCODE_OPTS --copyright --email"
          fi
          if [ "${{ github.event.inputs.enable_metadata_scan }}" = "true" ]; then
            SCANCODE_OPTS="$SCANCODE_OPTS --url --info"
          fi
          if [ "${{ github.event.inputs.enable_package }}" = "true" ]; then
            SCANCODE_OPTS="$SCANCODE_OPTS --package"
          fi

          OUT_PREFIX="$GITHUB_WORKSPACE/scancode_${SCAN_LABEL}"
          IN_PATH="$GITHUB_WORKSPACE/$INPUT_PATH"

          ./scancode $SCANCODE_OPTS --json-pp "${OUT_PREFIX}.json" "$IN_PATH"

          if [ "${{ github.event.inputs.enable_sbom_export }}" = "true" ]; then
            ./scancode --spdx-tv   "${OUT_PREFIX}.spdx.tv"   "$IN_PATH"
            ./scancode --spdx-rdf  "${OUT_PREFIX}.spdx.rdf"  "$IN_PATH"
            ./scancode --cyclonedx-json "${OUT_PREFIX}.cdx.json" "$IN_PATH"
          fi

          echo "OUT_PREFIX=$OUT_PREFIX" >> $GITHUB_ENV

      - name: Convert JSON → CSV + Excel
        run: |
          python3 - <<'EOF'
          import pandas as pd, json, glob, os

          lic_rows, file_rows, copy_rows, dep_rows = [], [], [], []

          for jf in glob.glob("scancode_*.json"):
              with open(jf, "r", encoding="utf-8") as f:
                  try:
                      data = json.load(f)
                  except Exception:
                      continue

              # --- license detections ---
              for lic in data.get("license_detections", []):
                  for ref in lic.get("reference_matches", []):
                      lic_rows.append({
                          "file_path": ref.get("from_file"),
                          "license_expression": lic.get("license_expression"),
                          "license_expression_spdx": lic.get("license_expression_spdx"),
                          "start_line": ref.get("start_line"),
                          "end_line": ref.get("end_line"),
                          "score": ref.get("score"),
                          "rule_url": ref.get("rule_url"),
                          "matched_text": ref.get("matched_text")[:200], # truncate long text
                      })

              # --- files (dynamic details) ---
              for fi in data.get("files", []):
                  file_rows.append({
                      "path": fi.get("path"),
                      "type": fi.get("type"),
                      "licenses": "; ".join([l.get("spdx_license_key","") for l in fi.get("licenses", []) if l.get("spdx_license_key")]),
                      "copyrights": "; ".join([c.get("value","") for c in fi.get("copyrights", []) if c.get("value")]),
                      "authors": "; ".join([a.get("value","") for a in fi.get("authors", []) if a.get("value")]),
                      "emails": "; ".join([e.get("value","") for e in fi.get("emails", []) if e.get("value")]),
                      "urls": "; ".join([u.get("value","") for u in fi.get("urls", []) if u.get("value")]),
                  })

                  for c in fi.get("copyrights", []):
                      copy_rows.append({"file": fi.get("path"), "copyright": c.get("value")})
                  for a in fi.get("authors", []):
                      copy_rows.append({"file": fi.get("path"), "author": a.get("value")})
                  for e in fi.get("emails", []):
                      copy_rows.append({"file": fi.get("path"), "email": e.get("value")})

              # --- dependencies ---
              for dep in data.get("dependencies", []):
                  dep_rows.append({
                      "purl": dep.get("purl"),
                      "requirement": dep.get("extracted_requirement"),
                      "scope": dep.get("scope"),
                      "is_runtime": dep.get("is_runtime"),
                      "is_optional": dep.get("is_optional"),
                      "is_direct": dep.get("is_direct"),
                      "datafile": dep.get("datafile_path"),
                  })

          # DataFrames
          df_lic  = pd.DataFrame(lic_rows)
          df_files = pd.DataFrame(file_rows)
          df_copy = pd.DataFrame(copy_rows)
          df_deps = pd.DataFrame(dep_rows)

          # --- Summary ---
          summary_blocks = []
          if not df_lic.empty:
              lic_summary = df_lic.groupby("license_expression_spdx")["file_path"].count().reset_index()
              lic_summary.rename(columns={"file_path":"count"}, inplace=True)
              lic_summary.insert(0,"Category","Licenses")
              summary_blocks.append(lic_summary)

          if not df_copy.empty:
              copy_summary = df_copy.melt(id_vars=["file"], value_name="value").dropna()
              copy_summary = copy_summary[["value","file"]]
              copy_summary.insert(0,"Category","Copyrights/Authors/Emails")
              summary_blocks.append(copy_summary)

          if not df_deps.empty:
              dep_summary = df_deps[["purl","requirement","scope"]].copy()
              dep_summary.insert(0,"Category","Dependencies")
              summary_blocks.append(dep_summary)

          df_summary = pd.concat(summary_blocks, ignore_index=True) if summary_blocks else pd.DataFrame()

          # Save Excel
          scan_label = os.getenv("SCAN_LABEL", "scancode")
          out_xlsx = f"scancode_{scan_label}.xlsx"

          with pd.ExcelWriter(out_xlsx) as w:
              if not df_lic.empty: df_lic.to_excel(w,"Licenses_Detail",index=False)
              if not df_files.empty: df_files.to_excel(w,"Files_Detail",index=False)
              if not df_copy.empty: df_copy.to_excel(w,"Copyrights_Detail",index=False)
              if not df_deps.empty: df_deps.to_excel(w,"Dependencies",index=False)
              if not df_summary.empty: df_summary.to_excel(w,"Summary",index=False)

          print(f"✅ Wrote Excel: {out_xlsx}")
          EOF

      - name: Upload ScanCode reports
        uses: actions/upload-artifact@v4
        with:
          name: scancode-reports-${{ env.SCAN_LABEL }}
          path: |
            scancode_${{ env.SCAN_LABEL }}.json
            scancode_${{ env.SCAN_LABEL }}.xlsx
            scancode_${{ env.SCAN_LABEL }}.spdx.tv
            scancode_${{ env.SCAN_LABEL }}.spdx.rdf
            scancode_${{ env.SCAN_LABEL }}.cdx.json
